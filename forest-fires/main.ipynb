{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qLEpFSMPDHpX"
   },
   "source": [
    "# Установка библиотек и их зависимостей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v03rMYfr-YGf"
   },
   "source": [
    "Установка зависимостей используемых модулей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mV1OVPBGf_SD"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install -q numpy>=1.18.5\n",
    "    !pip install -q pandas>=1.0.5\n",
    "    !pip install -q seaborn>=0.9.0\n",
    "    !pip install -q matplotlib>=2.1.0\n",
    "    !pip install -q scikit-learn>=0.23.2\n",
    "    !pip install -q ucimlrepo>=0.0.7\n",
    "    !pip install -q scipy>=1.14.1\n",
    "    !pip install -q tqdm>=4.66.5\n",
    "    !pip install -q pprintpp>=0.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aP-gbt_R-R5c"
   },
   "source": [
    "Необходимые ``import``'ы для выполнения задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mu3OXi0Vj6kU"
   },
   "outputs": [],
   "source": [
    "# Essential\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import scipy as scp\n",
    "\n",
    "# Scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Scikit-learn preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# Scikit-learn models\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "# Scikit-learn model selection\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, GridSearchCV\n",
    "# Scikit-learn metrics\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "# Utilities\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from copy import deepcopy\n",
    "from tqdm.notebook import tqdm\n",
    "from zlib import crc32\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5nu2ZSFDUs_"
   },
   "source": [
    "# Генератор задания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESx4t879-h_-"
   },
   "source": [
    "Генератор задания, взятый по [этой ссылке](https://github.com/andriygav/MachineLearningSeminars/blob/master/hometask/task1-1/generator.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tH31oYFYCtxj"
   },
   "outputs": [],
   "source": [
    "types = ['regression', 'classification']\n",
    "datasets = {'regression': [{'name': 'Servo Data Set',\n",
    "                            'url': 'https://archive.ics.uci.edu/ml/datasets/Servo'},\n",
    "                           {'name': 'Forest Fires Data Set',\n",
    "                            'url': 'https://archive.ics.uci.edu/ml/datasets/Forest+Fires'},\n",
    "                           {'name': 'Boston Housing Data Set',\n",
    "                            'url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html#sklearn.datasets.load_boston'},\n",
    "                           {'name': 'Diabetes Data Set',\n",
    "                            'url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes'}],\n",
    "            'classification': [{'name': 'Spambase Data Set',\n",
    "                                'url': 'https://archive.ics.uci.edu/ml/datasets/Spambase'},\n",
    "                               {'name': 'Wine Data Set',\n",
    "                                'url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine'},\n",
    "                               {'name': 'Breast Cancer Data Set',\n",
    "                                'url': 'https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer'},\n",
    "                               {'name': 'MNIST',\n",
    "                                'url': 'http://yann.lecun.com/exdb/mnist/'}]}\n",
    "methods = {'regression': ['Линейная регрессия',\n",
    "                          'Перцептрон',\n",
    "                          'Надарая-Ватсона',\n",
    "                          'SVR'],\n",
    "           'classification': ['Логистическая регрессия',\n",
    "                              'Перцептрон',\n",
    "                              'k-ближайших соседей',\n",
    "                              'Метод потенциальных функций',\n",
    "                              'Метод Парзеновского окна',\n",
    "                              'SVM']}\n",
    "task = dict()\n",
    "task['mail'] = \"subkhankulov.rr@phystech.edu\"\n",
    "task['id'] = crc32(task['mail'].encode('utf-8'))\n",
    "np.random.seed(task['id'])\n",
    "task['type'] = np.random.choice(types)\n",
    "task['dataset'] = np.random.choice(datasets[task['type']])\n",
    "task['method'] = np.random.choice(\n",
    "    methods[task['type']], size=3, replace=False).tolist()\n",
    "\n",
    "task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsNtzKJcfFEX"
   },
   "source": [
    "# Формулировка задания\n",
    "Требуется:\n",
    "- Провести анализ выборки:\n",
    "  - Определить тип признаков.\n",
    "  - Выполнить визуальный анализ данных.\n",
    "- Выполнить препроцесинг данных:\n",
    "  - Преобразовать категориальные признаки в вещественные.\n",
    "  - Отнормировать признаки.\n",
    "- Провести эксперимент для предложенных методов (Перцептрон, Надарая-Ватсона, SVR):\n",
    "  - Выполнить подбор гиперпараметров.\n",
    "  - Подобрать регуляризаторы.\n",
    "  - Получить итоговые модели.\n",
    "- Описать полученные результаты:\n",
    "  - Какая модель лучше и почему.\n",
    "  - С какими проблемами столкнулись во время выполнения, возможно недочеты стандартных библиотек.\n",
    "  - Совпадают ли полученные результаты с ожидаемыми результатами.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fCx8JPz-2hw"
   },
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "Whm1xHd4fS4S",
    "outputId": "c60b53f4-c5f9-4e81-ac7e-f3907ed5b9aa"
   },
   "outputs": [],
   "source": [
    "# Получаем датасет\n",
    "forest_fires = fetch_ucirepo(id=162)\n",
    "\n",
    "# Вывод метаданных\n",
    "pprint(forest_fires.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Признаки\n",
    "pprint(forest_fires.data.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказываемое значение\n",
    "pprint(forest_fires.data.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Датасет в качестве ``pandas DataFrame``\n",
    "df = forest_fires.data.features\n",
    "df['target'] = forest_fires.data.targets\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_psM2lTEhlp9"
   },
   "source": [
    "# Aнализ выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "id": "71ciRfE0_BVq",
    "outputId": "8abf1082-6d34-44ab-c1c2-5cf3e35f2560"
   },
   "outputs": [],
   "source": [
    "# Информация о переменных в датасете\n",
    "pprint(forest_fires.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- В выборке имеем 517 объектов, 12 признаков.\n",
    "- ``missing_values`` для всех признаков имеет значение 0, следовательно все признаки определены для каждого объекта в выборке.\n",
    "- Имеем признаки различных типов - представленные целочисленными и действительными значениями, а также категориальные признаки:\n",
    "  - Целочисленные: ``X``, ``Y``, ``DMC``, ``RH``, ``rain``.\n",
    "  - Действительные значения: ``FFMC``, ``DS``, ``ISI``, ``temp``,``wind``.\n",
    "  - Категориальные: ``month`` и ``day``.\n",
    "- Предсказываемое значение (``target``) ``area`` является непрерывной величиной. Имеем задачу регрессии. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отделяем численные и категориальные признаки\n",
    "categorical_features = [\"month\", \"day\"]\n",
    "numerical_features = list(set(df.columns) - set(categorical_features) - set([\"target\"]))\n",
    "\n",
    "print(f\"Категориальные признаки: {categorical_features}\")\n",
    "print(f\"Численные признаки: {numerical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lFxh8rIihm6t"
   },
   "outputs": [],
   "source": [
    "# Случайный срез из данных\n",
    "df.sample(5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SmlHdIL_h14N"
   },
   "outputs": [],
   "source": [
    "# Описание численных признаков\n",
    "df[numerical_features].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем видеть, что признак ``rain`` имеет малое стандартное отклонение и практически для всех объектов выборки имеет нулевое значение. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Описание категориальных признаков\n",
    "df[categorical_features].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Категориальные признаки:\n",
    "  - ``month`` - месяц, в формате строки.\n",
    "  - ``day`` - день недели, в формате строки.\n",
    "\n",
    "При препроцессинге данных необходимо перевести данные признаки в численный формат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AnEj38opXWc"
   },
   "source": [
    "# Препроцесинг данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отделяем признаки и предсказываемое значение\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "pprint(X)\n",
    "pprint(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.sample(5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sample(5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем категориальные признаки в численный формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9x1deCSuVH1"
   },
   "outputs": [],
   "source": [
    "# Кодирование признаков\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(X[categorical_features])\n",
    "\n",
    "# Создание DataFrame c читаемыми именами кодированных признаков\n",
    "encoded_features = encoder.get_feature_names_out(categorical_features)\n",
    "X_encoded_df = pd.DataFrame(X_encoded, columns=encoded_features, index=X.index)\n",
    "X_encoded_df.sample(5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим выборку на обучающую и тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(f\"Размер обучающей выборки составляет {len(X_train.index)} объектов.\")\n",
    "print(f\"Размер тестовой выборки составляет {len(X_test.index)} объектов.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.sample(5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.sample(5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведем нормировку численных признаков. \n",
    "\n",
    "'Обучание' ``scaler``'а производим на обучающей выборке, чтобы не вносить в модель информацию о предсказываемом значении.\n",
    "\n",
    "Для координат нормировка представляет растяжение и перенос координат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hy4dt8snx1xo"
   },
   "outputs": [],
   "source": [
    "# Обучаем 'scaler' на обучающей выборке\n",
    "x_scaler = StandardScaler()\n",
    "x_scaler.fit(X[numerical_features])\n",
    "\n",
    "# Нормируем численные признаки во всей выборке\n",
    "X_scaled = x_scaler.transform(X[numerical_features])\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=numerical_features, index=X.index)\n",
    "X_scaled_df.sample(5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединяем скалированные численные признаки и кодированные категориальные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proc = np.hstack((X_scaled, X_encoded))\n",
    "X_proc_df = pd.concat([X_scaled_df, X_encoded_df], axis=1)\n",
    "X_proc_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее скалируем значение ``target``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = np.log(np.ones(len(y)) + y)\n",
    "# y_scaled = (y - y.mean()) / y.std()\n",
    "# y_proc_df = pd.DataFrame(y_scaled, columns=[\"target\"], index=y.index)\n",
    "y_proc_df = pd.DataFrame(np.log(np.ones(len(y)) + y), columns=[\"target\"], index=y.index)\n",
    "y_proc_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторяем деление выборки на обучающую и тестовую. Множества объектов обучающей и тестовой выборок совпадают с полученными раннее, только теперь признаки в них отнормированны и закодированы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proc_train, X_proc_test, y_proc_train, y_proc_test = train_test_split(X_proc_df, y_proc_df, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proc_train.sample(5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proc_train.sample(5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proc_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proc_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proc_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proc_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведем анализ взаимной зависимости признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(X_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proc_df_min = y_proc_df.min()[0]\n",
    "y_proc_df_max = y_proc_df.max()[0]\n",
    "\n",
    "y_step = round((y_proc_df_max - y_proc_df_min) / 10, 2)\n",
    "\n",
    "for feature in X_proc_df[numerical_features].columns:\n",
    "    x_min = min(X_proc_df[feature])\n",
    "    x_max = max(X_proc_df[feature])\n",
    "    x_step = (x_max - x_min) / 8\n",
    "    \n",
    "    plt.figure(figsize=[4,3])\n",
    "    plt.xlim(x_min, x_max)\n",
    "\n",
    "    plt.xticks(np.arange(x_min - x_step, x_max + 2 * x_step, x_step))\n",
    "    plt.yticks(np.arange(y_proc_df_min - y_step, y_proc_df_max + 2 * y_step, y_step))\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.title(feature)\n",
    "    plt.xlabel(\"feature value\")\n",
    "    plt.ylabel(\"target value\")\n",
    "\n",
    "    plt.scatter(X_proc_df[feature], y_proc_df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графиков зависимости предсказываемого значения от признаков, можно сделать следующие выводы:\n",
    "  - Предсказывамое значение принимает большие значения лишь при нулевом значении ``rain``, вероятно существует зависимость предсказываемого значения от признака ``rain``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5L0wRyYvp372"
   },
   "source": [
    "# Эксперименты для предложенных методов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8w5ldrCRp94Y"
   },
   "source": [
    "## Перцептрон"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ud3DEzC-3Ho-"
   },
   "outputs": [],
   "source": [
    "# Параметры конструктора\n",
    "MLPRegressor().get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список гиперпараметров, которые будут подбираться:\n",
    "  - ``hidden_layer_sizes`` - количество и размер скрытых слоев\n",
    "  - ``activation`` - функция активации\n",
    "  - ``alpha`` - 'сила' L2-регуляризации\n",
    "  - ``solver`` - использование классического SGD или оптимизации Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Размер скрытого слоя\n",
    "hidden_layer_dims = [10, 50, 100, 150]\n",
    "# Количество скрытых слоев\n",
    "hidden_layer_nums = [1, 2, 3]\n",
    "\n",
    "# Всевозможные комбинации вида 'num слоев размера dim'. \n",
    "hidden_layer_sizes = []\n",
    "for num in hidden_layer_nums:\n",
    "    for dim in hidden_layer_dims:\n",
    "        hidden_layer_sizes.append([dim] * num)\n",
    "\n",
    "# Сетка параметров\n",
    "perceptron_param_grid = {\n",
    "  'hidden_layer_sizes': hidden_layer_sizes, \n",
    "  'activation': [\"logistic\", \"tanh\", \"relu\"],\n",
    "  'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 5.0, 10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0],\n",
    "  'solver': [\"sgd\", \"adam\"]\n",
    "}\n",
    "pprint(perceptron_param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем следующие метрики:\n",
    "  - ``neg_mean_absolute_error`` - Mean absolute error regression loss\n",
    "  - ``neg_root_mean_squared_error`` - Root mean squared error regression loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_metrics = {\n",
    "    'neg_mean_absolute_error': mean_absolute_error,\n",
    "    'neg_root_mean_squared_error': root_mean_squared_error\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель - персептрон."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = MLPRegressor(\n",
    "  max_iter=20000, # Установим максимальное количество итераций больше дефолтного значения (1000)\n",
    "  random_state=0 # Фиксируем seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_best = {}\n",
    "perceptron_best_params = {}\n",
    "perceptron_best_score = {}\n",
    "\n",
    "# Отдельно ищем лучшие параметры для разных метрик\n",
    "for scoring in perceptron_metrics.keys():\n",
    "    grid_search = GridSearchCV(\n",
    "      estimator=perceptron, \n",
    "      param_grid=perceptron_param_grid,\n",
    "      scoring=scoring,\n",
    "      n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Производим поиск лучших параметров\n",
    "    grid_search.fit(X_proc_train, y_proc_train.values.ravel())\n",
    "\n",
    "    # Запоминаем результаты: лучшая модель, её параметры и score\n",
    "    perceptron_best[scoring] = grid_search.best_estimator_\n",
    "    perceptron_best_params[scoring] = grid_search.best_params_\n",
    "    perceptron_best_score[scoring] = grid_search.best_score_\n",
    "\n",
    "    # Выводим результаты\n",
    "    print(f\"Scoring: {scoring}\")\n",
    "    print(f\"Best score: {round(perceptron_best_score[scoring], 6)}\")\n",
    "    print(\"Best parameters:\")\n",
    "    pprint(perceptron_best_params[scoring])\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Результаты на тестовой выборке\n",
    "    y_pred = perceptron_best[scoring].predict(X_proc_test)\n",
    "    perceptron_test_score = - perceptron_metrics[scoring](y_proc_test, y_pred)\n",
    "    print(f\"Test score: {round(perceptron_test_score, 6)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнения полученных результатов с приведёнными в описании датасета и уже проведенных на нем экспериментов, произведем обратное преобразование ``y_pred`` и ``y_proc_test`` и посчитаем метрику на полученных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scoring in perceptron_metrics.keys():\n",
    "    print(f\"Scoring: {scoring}\")\n",
    "    y_pred_trans = np.expm1(perceptron_best[scoring].predict(X_proc_test))\n",
    "    svr_test_score = perceptron_metrics[scoring](np.expm1(y_proc_test), y_pred_trans)\n",
    "    print(f\"Test score for back-transformed: {round(svr_test_score, 6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4G5UPH87qA1x"
   },
   "source": [
    "## Надарая-Ватсона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5P6eVxIgXvz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7zQCkDoqAdT"
   },
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список гиперпараметров, которые будут подбираться:\n",
    "  - ``kernel`` - функция ядра\n",
    "  - ``gamma`` - коэффициент для ядерных функций ``rbf``, ``poly`` и ``sigmoid``\n",
    "  - ``C`` - параметр регуляризации. Сила регуляризации обратно пропорциональна C. Должнен быть строго положительным. Penalty - l2 в квадрате"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XyQkfaRNpp3b"
   },
   "outputs": [],
   "source": [
    "# Сетка параметров\n",
    "svr_param_grid = {\n",
    "  'kernel': [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "  'gamma': [\"scale\", \"auto\"],\n",
    "  'C': [0.001, 0.005, 0.1, 0.5, 1.0, 5.0, 10.0, 25.0, 50.0]\n",
    "}\n",
    "pprint(svr_param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем следующие метрики:\n",
    "  - ``neg_mean_absolute_error`` - Mean absolute error regression loss\n",
    "  - ``neg_root_mean_squared_error`` - Root mean squared error regression loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XyQkfaRNpp3b"
   },
   "outputs": [],
   "source": [
    "svr_metrics = {\n",
    "    'neg_mean_absolute_error': mean_absolute_error,\n",
    "    'neg_root_mean_squared_error': root_mean_squared_error\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_best = {}\n",
    "svr_best_params = {}\n",
    "svr_best_score = {}\n",
    "\n",
    "# Отдельно ищем лучшие параметры для разных метрик\n",
    "for scoring in svr_metrics.keys():\n",
    "    grid_search = GridSearchCV(\n",
    "      estimator=SVR(), \n",
    "      param_grid=svr_param_grid,\n",
    "      scoring=scoring,\n",
    "      n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Производим поиск лучших параметров\n",
    "    grid_search.fit(X_proc_train, y_proc_train.values.ravel())\n",
    "    \n",
    "    svr_best[scoring] = grid_search.best_estimator_\n",
    "    svr_best_params[scoring] = grid_search.best_params_\n",
    "    svr_best_score[scoring] = grid_search.best_score_\n",
    "\n",
    "    # Выводим результаты\n",
    "    print(f\"Scoring: {scoring}\")\n",
    "    print(f\"Best score: {round(svr_best_score[scoring], 6)}\")\n",
    "    print(\"Best parameters:\")\n",
    "    pprint(svr_best_params[scoring])\n",
    "\n",
    "    # Результаты на тестовой выборке\n",
    "    y_test_pred = svr_best[scoring].predict(X_proc_test)\n",
    "    svr_test_score = svr_metrics[scoring](y_proc_test, y_test_pred)\n",
    "    print(f\"Test score: {round(svr_test_score, 6)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично, произведем обратное преобразование y_pred и y_proc_test и посчитаем метрику на полученных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scoring in svr_metrics.keys():\n",
    "    print(f\"Scoring: {scoring}\")\n",
    "    y_pred_trans = np.expm1(svr_best[scoring].predict(X_proc_test))\n",
    "    svr_test_score = svr_metrics[scoring](np.expm1(y_proc_test), y_pred_trans)\n",
    "    print(f\"Test score for back-transformed: {round(svr_test_score, 6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpzJOjddgR6W"
   },
   "source": [
    "# Описание полученных результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IfRowdDKgUpW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
